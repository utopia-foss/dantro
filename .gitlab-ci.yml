---
stages:
  - prep
  - test
  - test_minimal_deps
  - build
  - deploy
  - post_deploy

variables:
  # Documentation server configuration
  DOC_HOST: root@hermes.iup.uni-heidelberg.de
  DOC_PORT: 2023      # ... forwards to dantro_doc_server container. root ok ;)
  DOC_REMOTE_BASE_DIR: /var/dantro_doc
  DOC_REMOTE_PATH: $DOC_REMOTE_BASE_DIR/$CI_COMMIT_REF_SLUG
  DOC_REMOTE_URL: https://hermes.iup.uni-heidelberg.de/dantro_doc


# For the deployment of the documentation, the jobs authenticate themselves
# via a keypair with the doc server. This is the read-only deployment key
# for the Utopia project, stored as SSH_PRIVATE_KEY CI/CD variable.
.ssh_access: &ssh_access
  before_script:
    # Instructions:
    #   https://docs.gitlab.com/ce/ci/ssh_keys/
    # Run ssh-agent (inside the build environment)
    - eval $(ssh-agent -s)

    # Add the SSH key stored in SSH_PRIVATE_KEY variable to the agent store
    # We're using tr to fix line endings which makes ed25519 keys work
    # without extra base64 encoding.
    # https://gitlab.com/gitlab-examples/ssh-private-key/issues/1#note_48526556
    - echo "$SSH_PRIVATE_KEY" | tr -d '\r' | ssh-add - > /dev/null

    # Create the SSH directory and give it the right permissions
    - mkdir -p ~/.ssh
    - chmod 700 ~/.ssh

    # Add the known hosts lists to ensure this ssh connection is the right one
    - echo "$SSH_KNOWN_HOSTS" > ~/.ssh/known_hosts
    - chmod 644 ~/.ssh/known_hosts


# -----------------------------------------------------------------------------
# -- Prep Stage ---------------------------------------------------------------
# ... doing some setup work

prep:noop:  # This is a no-op job, used as `needs` for build:docs
  stage: prep
  image: alpine:latest
  cache: {}
  variables:
    GIT_STRATEGY: none
  script:
    - echo "Let's get testing!"
    - echo "(This is a workaround for 'https://gitlab.com/gitlab-org/gitlab/issues/30631')"


# -- Test Stage ---------------------------------------------------------------
# ... for testing with different python environments

test:py36: &test_defaults
  stage: test
  image: python:3.6
  before_script:
    - pip3 install tox
  script:
    - tox -e py36

test:py37:
  <<: *test_defaults
  image: python:3.7
  script:
    - tox -e py37

test:py38:
  <<: *test_defaults
  image: python:3.8
  script:
    - tox -e py38


# ... and again, this time with minimal versions of all dependencies

test_minimal_deps:py36: &test_minimal
  <<: *test_defaults
  stage: test_minimal_deps
  only:
    - master
    - tags
    - web
    - /^prepare-release-/i
    - /^137-/i  # FIXME remove
  allow_failure: true
  needs:
    - test:py36
  script:
    - tox -e py36-minimal_deps

test_minimal_deps:py37:
  <<: *test_minimal
  image: python:3.7
  needs:
    - test:py37
  script:
    - tox -e py37-minimal_deps

test_minimal_deps:py38:
  <<: *test_minimal
  image: python:3.8
  needs:
    - test:py38
  script:
    - tox -e py38-minimal_deps


# -- Build Stage --------------------------------------------------------------
# ... for building the documentation (and potentially more jobs)

build:docs:
  stage: build
  image: python:3.7
  allow_failure: true
  needs: ["prep:noop"]
  before_script:
    - pip3 install .[doc_deps]
  script:
    - cd doc
    - make doc
  after_script:
    # Append the error log such that it's more convenient to read
    - echo "-------- Errors emitted during building of documentation --------"
    - cat doc/build_errors.log

  artifacts:
    when: always
    name: "doc-$CI_COMMIT_REF_NAME"
    expire_in: 3h
    expose_as: Documentation Build Results - including error log
    paths:
      - doc/_build/html
      - doc/build_errors.log


# -- Deploy Stage -------------------------------------------------------------
# ... for deployment of the documentation, deployment of dantro to the PyPI
#     (and potentially more jobs)

# Deploy the documentation to a self-hosted web server
deploy:docs:
  stage: deploy
  image: &deploy_image ccees/utopia-base:v2.1  # overkill, but sshd installed
  <<: *ssh_access
  only:
    - branches@utopia/dantro
  dependencies:
    - build:docs
  needs:
    - build:docs
  script:
    # Create the directory on the remote, removing any prior version
    - echo "Creating empty remote directory $DOC_REMOTE_PATH ..."
    - ssh -p $DOC_PORT $DOC_HOST "rm -rf $DOC_REMOTE_PATH"
    - ssh -p $DOC_PORT $DOC_HOST "mkdir -p $DOC_REMOTE_PATH"

    # Copy the sphinx HTML output to the remote
    - echo "Uploading documentation to $DOC_REMOTE_PATH/ ..."
    - scp -P $DOC_PORT -pr doc/_build/html $DOC_HOST:$DOC_REMOTE_PATH/

    - echo "Finished. :)"

  environment:
    name: docs/$CI_COMMIT_REF_NAME
    url: $DOC_REMOTE_URL/$CI_COMMIT_REF_SLUG/html/
    on_stop: deploy:stop_docs

# Stop the deployed "docs" environment for this branch
# NOTE: This job is automatically executed if the original branch is deleted
#       (*GitLab Magic*) or someone stops the environment.
deploy:stop_docs:
  stage: deploy
  image: *deploy_image
  <<: *ssh_access
  when: manual          # ... but it is also triggered on branch deletion
  dependencies: []      # ... otherwise, the same dependencies as deploy:docs
                        #     are assumed, which leads to failing jobs if the
                        #     corresponding artifacts have expired
  variables:
    GIT_STRATEGY: none  # Don't check out the branch (might already be deleted)
  script:
    - echo "Removing remote directory $DOC_REMOTE_PATH ..."
    - ssh -p $DOC_PORT $DOC_HOST "rm -rf $DOC_REMOTE_PATH"
    - echo "It's gone. :)"

  environment:
    name: docs/$CI_COMMIT_REF_NAME
    action: stop

# Deploy dantro to PyPI
deploy:pypi:
  stage: deploy
  image: python:3.7
  <<: *ssh_access
  only: &to_deploy
    - tags    # Triggered when a new tag is added
    - web     # Use this for pre-release deployment
  script:
    # Define a regex for matching the tag name, see https://regex101.com/r/AsCCJo/2
    # Expects fully-qualified version specifiers, like v1.2.3 or v1.2.3a4
    # Does NOT accept tags like 1.2.3 (missing v) or v1.0 (missing patch version)
    - export VERSION_PATTERN="v([[:digit:]]+)\.([[:digit:]]+)\.([[:digit:]]+)([[:lower:]]\d+)?"
    # Before checking that the tag matches the expected pattern, check the regex
    # pattern with a few allowed versions.
    - "[[ \"v1.2.3\" =~ ${VERSION_PATTERN} ]]"
    - "[[ \"v1.23.4a5\" =~ ${VERSION_PATTERN} ]]"

    # Now do the actual check
    - "[[ ${CI_COMMIT_TAG} =~ ${VERSION_PATTERN} ]]"
    # Tag is of the correct form, yay!

    - pip install -U twine

    # Create distribution files
    - python setup.py sdist bdist_wheel

    # Check whether description will render correctly on PyPI
    - twine check dist/*

    # Upload to the TEST PyPI index (using separate credentials)
    - twine upload --repository-url https://test.pypi.org/legacy/ -u ${PYPI_TEST_USER} -p ${PYPI_TEST_PASSWORD} dist/*

    # If this worked, continue and upload to actual package index
    - twine upload -u ${PYPI_USER} -p ${PYPI_PASSWORD} dist/*


# -- Test Deploy Stage --------------------------------------------------------
# ... for testing the deployment to the PyPI (and potentially more jobs)

# Install dantro from the PyPI via pip to test automatic deployment
post_deploy:install_from_pypi:
  stage: post_deploy
  image: python:3.7
  only: *to_deploy
  needs:
    - "deploy:pypi"
  script:
    # Install the newly deployed dantro version via PyPI. The current version
    # number is given by the commit tag without the prefixed 'v'.
    - pip install dantro==${CI_COMMIT_TAG#v}
